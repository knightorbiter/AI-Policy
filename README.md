# MDP
This code computes the Markov Decision Process(MDP) utilities for states via the Value Iteration Algorithm.

# Instructions
Fire up your terminal, and type
```sh
$ python mdp.py
```
# Features
Suppport for displaying all calculations involved along with the iteration table.
Added final policy iteration computation and matrix display.
